{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To find out where the pyspark\n",
    "# import findspark\n",
    "# findspark.init()\n",
    "\n",
    "# # Creating Spark Context\n",
    "# from pyspark import SparkContext, SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import UserDefinedFunction as udf\n",
    "from pyspark.sql.types import StringType, IntegerType, DecimalType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"SimpleApp.py\"\"\"\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "logFile = \"/home/arditto_trianggada3/misc/\"  # Should be some file on your system\n",
    "spark = SparkSession.builder.appName(\"FirstSparkApp\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines with a: 12, lines with b: 1\n"
     ]
    }
   ],
   "source": [
    "logData = spark.read.text(logFile).cache()\n",
    "\n",
    "numAs = logData.filter(logData.value.contains('a')).count()\n",
    "numBs = logData.filter(logData.value.contains('b')).count()\n",
    "\n",
    "print(\"Lines with a: %i, lines with b: %i\" % (numAs, numBs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test read csv using pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "    .load(\"/home/arditto_trianggada3/Workspace/ds-ovo-test/dataset/trip_merge_4_fe_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['medallion',\n",
       " 'hack_license',\n",
       " 'vendor_id',\n",
       " 'rate_code',\n",
       " 'store_and_fwd_flag',\n",
       " 'pickup_datetime',\n",
       " 'dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_time_in_secs',\n",
       " 'trip_distance']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(medallion='91F6EB84975BBC867E32CB113C7C2CD5', hack_license='AD8751110E6292079EB10EB9481FE1A6', vendor_id='CMT', rate_code='1', store_and_fwd_flag='N', pickup_datetime='2013-04-04 18:47:45', dropoff_datetime='2013-04-04 19:00:25', passenger_count='1', trip_time_in_secs='759', trip_distance='2.5', pickup_longitude='-73.95785500000001', pickup_latitude='40.76532', dropoff_longitude='-73.97627299999999', dropoff_latitude='40.785647999999995', payment_type='CRD', fare_amount='11.0', surcharge='1.0', mta_tax='0.5', tip_amount='2.5', tolls_amount='0.0', total_amount='15.0', pickup_longitude_bin='-73.955', pickup_latitude_bin='40.77', dropoff_longitude_bin='-73.975', dropoff_latitude_bin='40.79', pickup_addr_zipcode='10065.0', pickup_addr_place='E 67th St', pickup_addr_neighborhood=None, pickup_addr_sublocal='Manhattan', pickup_addr_local='New York', pickup_addr_administrative_area_level_2='New York County', dropoff_addr_zipcode='10024.0', dropoff_addr_place='W 83rd St', dropoff_addr_neighborhood=None, dropoff_addr_sublocal='Manhattan', dropoff_addr_local='New York', dropoff_addr_administrative_area_level_2='New York County', pickup_to_dropoff_zipcode='10065.0_10024.0', pickup_to_dropoff_place='E 67th St_W 83rd St', pickup_to_dropoff_neighborhood='nan_nan', pickup_to_dropoff_sublocal='Manhattan_Manhattan', pickup_to_dropoff_local='New York_New York', pickup_to_dropoff_administrative_area_level_2='New York County_New York County', pickup_month='4', pickup_dayofweek='Thursday', pickup_hour='18', dropoff_month='4', dropoff_dayofweek='Thursday', dropoff_hour='19', is_public_holiday='0', is_weekend='0', is_holiday='0', trip_night='1', trip_late_night='0', trip_dist_euclidean='0.027430827694385086', trip_dist_manhattan='0.038745999999974856'),\n",
       " Row(medallion='C1B9DA774DC2BBC6DE27CE994E7F44A0', hack_license='E1B595FD55E4C82C1E213EB17438107A', vendor_id='CMT', rate_code='1', store_and_fwd_flag='N', pickup_datetime='2013-04-04 17:59:50', dropoff_datetime='2013-04-04 18:21:48', passenger_count='1', trip_time_in_secs='1318', trip_distance='3.6', pickup_longitude='-73.98288000000001', pickup_latitude='40.75499', dropoff_longitude='-74.009186', dropoff_latitude='40.715374', payment_type='CRD', fare_amount='16.5', surcharge='1.0', mta_tax='0.5', tip_amount='3.6', tolls_amount='0.0', total_amount='21.6', pickup_longitude_bin='-73.98', pickup_latitude_bin='40.755', dropoff_longitude_bin='-74.005', dropoff_latitude_bin='40.72', pickup_addr_zipcode='10036.0', pickup_addr_place='Verizon Plaza', pickup_addr_neighborhood=None, pickup_addr_sublocal='Manhattan', pickup_addr_local='New York', pickup_addr_administrative_area_level_2='New York County', dropoff_addr_zipcode='10007.0', dropoff_addr_place='Warren St', dropoff_addr_neighborhood=None, dropoff_addr_sublocal='Manhattan', dropoff_addr_local='New York', dropoff_addr_administrative_area_level_2='New York County', pickup_to_dropoff_zipcode='10036.0_10007.0', pickup_to_dropoff_place='Verizon Plaza_Warren St', pickup_to_dropoff_neighborhood='nan_nan', pickup_to_dropoff_sublocal='Manhattan_Manhattan', pickup_to_dropoff_local='New York_New York', pickup_to_dropoff_administrative_area_level_2='New York County_New York County', pickup_month='4', pickup_dayofweek='Thursday', pickup_hour='17', dropoff_month='4', dropoff_dayofweek='Thursday', dropoff_hour='18', is_public_holiday='0', is_weekend='0', is_holiday='0', trip_night='1', trip_late_night='0', trip_dist_euclidean='0.04755452756572936', trip_dist_manhattan='0.06592199999999337')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.limit(1000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medallion</th>\n",
       "      <th>hack_license</th>\n",
       "      <th>vendor_id</th>\n",
       "      <th>rate_code</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>pickup_datetime</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_time_in_secs</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>...</th>\n",
       "      <th>dropoff_month</th>\n",
       "      <th>dropoff_dayofweek</th>\n",
       "      <th>dropoff_hour</th>\n",
       "      <th>is_public_holiday</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_holiday</th>\n",
       "      <th>trip_night</th>\n",
       "      <th>trip_late_night</th>\n",
       "      <th>trip_dist_euclidean</th>\n",
       "      <th>trip_dist_manhattan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91F6EB84975BBC867E32CB113C7C2CD5</td>\n",
       "      <td>AD8751110E6292079EB10EB9481FE1A6</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-04-04 18:47:45</td>\n",
       "      <td>2013-04-04 19:00:25</td>\n",
       "      <td>1</td>\n",
       "      <td>759</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027430827694385086</td>\n",
       "      <td>0.038745999999974856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1B9DA774DC2BBC6DE27CE994E7F44A0</td>\n",
       "      <td>E1B595FD55E4C82C1E213EB17438107A</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-04-04 17:59:50</td>\n",
       "      <td>2013-04-04 18:21:48</td>\n",
       "      <td>1</td>\n",
       "      <td>1318</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.04755452756572936</td>\n",
       "      <td>0.06592199999999337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9BA84250355AB3FC031C9252D395BF8A</td>\n",
       "      <td>16BB0D96A0DCC853AEC7F55C8D6C71E0</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-04-04 18:12:01</td>\n",
       "      <td>2013-04-04 18:25:24</td>\n",
       "      <td>1</td>\n",
       "      <td>799</td>\n",
       "      <td>1.9</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026041115375480605</td>\n",
       "      <td>0.03564399999997647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>205A696DF62AD03C88DA8C5EC5248639</td>\n",
       "      <td>579C41EA5EC846F8B641A42F9EE3E855</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-04-04 20:12:57</td>\n",
       "      <td>2013-04-04 20:29:55</td>\n",
       "      <td>1</td>\n",
       "      <td>1017</td>\n",
       "      <td>3.6</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04759690756761306</td>\n",
       "      <td>0.06103600000000142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EE75E5927D00739AC342810C336A825E</td>\n",
       "      <td>1B4E92431F9DA4D49874EC76E769E874</td>\n",
       "      <td>CMT</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2013-04-05 02:48:11</td>\n",
       "      <td>2013-04-05 02:51:21</td>\n",
       "      <td>2</td>\n",
       "      <td>189</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.008904293907999591</td>\n",
       "      <td>0.012520000000002085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          medallion                      hack_license  \\\n",
       "0  91F6EB84975BBC867E32CB113C7C2CD5  AD8751110E6292079EB10EB9481FE1A6   \n",
       "1  C1B9DA774DC2BBC6DE27CE994E7F44A0  E1B595FD55E4C82C1E213EB17438107A   \n",
       "2  9BA84250355AB3FC031C9252D395BF8A  16BB0D96A0DCC853AEC7F55C8D6C71E0   \n",
       "3  205A696DF62AD03C88DA8C5EC5248639  579C41EA5EC846F8B641A42F9EE3E855   \n",
       "4  EE75E5927D00739AC342810C336A825E  1B4E92431F9DA4D49874EC76E769E874   \n",
       "\n",
       "  vendor_id rate_code store_and_fwd_flag      pickup_datetime  \\\n",
       "0       CMT         1                  N  2013-04-04 18:47:45   \n",
       "1       CMT         1                  N  2013-04-04 17:59:50   \n",
       "2       CMT         1                  N  2013-04-04 18:12:01   \n",
       "3       CMT         1                  N  2013-04-04 20:12:57   \n",
       "4       CMT         1                  N  2013-04-05 02:48:11   \n",
       "\n",
       "      dropoff_datetime passenger_count trip_time_in_secs trip_distance  ...  \\\n",
       "0  2013-04-04 19:00:25               1               759           2.5  ...   \n",
       "1  2013-04-04 18:21:48               1              1318           3.6  ...   \n",
       "2  2013-04-04 18:25:24               1               799           1.9  ...   \n",
       "3  2013-04-04 20:29:55               1              1017           3.6  ...   \n",
       "4  2013-04-05 02:51:21               2               189           0.7  ...   \n",
       "\n",
       "  dropoff_month dropoff_dayofweek dropoff_hour is_public_holiday is_weekend  \\\n",
       "0             4          Thursday           19                 0          0   \n",
       "1             4          Thursday           18                 0          0   \n",
       "2             4          Thursday           18                 0          0   \n",
       "3             4          Thursday           20                 0          0   \n",
       "4             4            Friday            2                 0          0   \n",
       "\n",
       "  is_holiday trip_night trip_late_night   trip_dist_euclidean  \\\n",
       "0          0          1               0  0.027430827694385086   \n",
       "1          0          1               0   0.04755452756572936   \n",
       "2          0          1               0  0.026041115375480605   \n",
       "3          0          1               1   0.04759690756761306   \n",
       "4          0          0               1  0.008904293907999591   \n",
       "\n",
       "    trip_dist_manhattan  \n",
       "0  0.038745999999974856  \n",
       "1   0.06592199999999337  \n",
       "2   0.03564399999997647  \n",
       "3   0.06103600000000142  \n",
       "4  0.012520000000002085  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14802407"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation to Raw Data using Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = spark.read\\\n",
    "#     .format(\"com.databricks.spark.csv\")\\\n",
    "#     .option(\"header\", \"true\") \\\n",
    "#     .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "#     .load(\"/home/arditto_trianggada3/Workspace/ds-ovo-test/dataset/trip_data_4.csv\")\n",
    "\n",
    "# df_fare = spark.read\\\n",
    "#     .format(\"com.databricks.spark.csv\")\\\n",
    "#     .option(\"header\", \"true\") \\\n",
    "#     .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "#     .load(\"/home/arditto_trianggada3/Workspace/ds-ovo-test/dataset/trip_fare_4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = spark.read.table(\"nyc_taxi_db.trip_data_4\")\n",
    "df_fare = spark.read.table(\"nyc_taxi_db.trip_fare_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcol = [x.strip() for x in df_data.columns]\n",
    "for i in range(len(lcol)):\n",
    "    df_data = df_data.withColumnRenamed(df_data.columns[i], lcol[i])\n",
    "    \n",
    "lcol = [x.strip() for x in df_fare.columns]\n",
    "for i in range(len(lcol)):\n",
    "    df_fare = df_fare.withColumnRenamed(df_fare.columns[i], lcol[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.createOrReplaceTempView(\"tbl_df_data\")\n",
    "df_fare.createOrReplaceTempView(\"tbl_df_fare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    t0.*,\n",
    "    t1.payment_type,\n",
    "    t1.fare_amount,\n",
    "    t1.surcharge,\n",
    "    t1.mta_tax,\n",
    "    t1.tip_amount,\n",
    "    t1.tolls_amount,\n",
    "    t1.total_amount\n",
    "FROM tbl_df_data t0\n",
    "JOIN tbl_df_fare t1 ON\n",
    "    (t0.medallion = t1.medallion) AND (t0.hack_license = t1.hack_license) AND (t0.vendor_id = t1.vendor_id) AND (t0.pickup_datetime = t1.pickup_datetime)\n",
    "\"\"\")\n",
    "\n",
    "df_merge.createOrReplaceTempView(\"tbl_df_merge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_merge\n",
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "BB = (-74.25, -73.75, 40.60, 41.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.filter(\"\"\"\n",
    "(pickup_longitude>={}) AND (pickup_longitude<={}) AND (dropoff_longitude<={}) AND (dropoff_longitude<={}) AND\n",
    "(pickup_latitude>={}) AND (pickup_latitude<={}) AND (dropoff_latitude<={}) AND (dropoff_latitude<={})\n",
    "\"\"\".format(BB[0],BB[1],BB[0],BB[1],BB[2],BB[3],BB[2],BB[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this plot and further analysis, we need a function to calculate the distance in miles between locations in lon,lat coordinates.\n",
    "# This function is based on https://stackoverflow.com/questions/27928/\n",
    "# calculate-distance-between-two-latitude-longitude-points-haversine-formula \n",
    "# return distance in miles\n",
    "def distance(lat1, lon1, lat2, lon2):\n",
    "    p = 0.017453292519943295 # Pi/180\n",
    "    a = 0.5 - np.cos((lat2 - lat1) * p)/2 + np.cos(lat1 * p) * np.cos(lat2 * p) * (1 - np.cos((lon2 - lon1) * p)) / 2\n",
    "    return 0.6213712 * 12742 * np.arcsin(np.sqrt(a)) # 2*R*asin...\n",
    "\n",
    "# First calculate two arrays with datapoint density per sq mile\n",
    "n_lon, n_lat = 100, 90 # number of grid bins per longitude, latitude dimension\n",
    "density_pickup, density_dropoff = np.zeros((n_lat, n_lon)), np.zeros((n_lat, n_lon)) # prepare arrays\n",
    "\n",
    "# To calculate the number of datapoints in a grid area, the numpy.digitize() function is used. \n",
    "# This function needs an array with the (location) bins for counting the number of datapoints\n",
    "# per bin.\n",
    "bins_lon = np.zeros(n_lon+1) # bin\n",
    "bins_lat = np.zeros(n_lat+1) # bin\n",
    "delta_lon = (BB[1]-BB[0]) / n_lon # bin longutide width\n",
    "delta_lat = (BB[3]-BB[2]) / n_lat # bin latitude height\n",
    "bin_width_miles = distance(BB[2], BB[1], BB[2], BB[0]) / n_lon # bin width in miles\n",
    "bin_height_miles = distance(BB[3], BB[0], BB[2], BB[0]) / n_lat # bin height in miles\n",
    "for i in range(n_lon+1):\n",
    "    bins_lon[i] = BB[0] + i * delta_lon\n",
    "for j in range(n_lat+1):\n",
    "    bins_lat[j] = BB[2] + j * delta_lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def digitize_lonlat(x, bins):\n",
    "#     res = np.digitize(x, bins)\n",
    "#     return res\n",
    "\n",
    "# spark.udf.register(\"udf_digitize_lon\", lambda x: digitize_lonlat(x,bins_lon), IntegerType())\n",
    "# spark.udf.register(\"udf_digitize_lat\", lambda x: digitize_lonlat(x,bins_lat), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.digitize_lat(x)>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def digitize_lon(x):\n",
    "    res = np.digitize(x, bins_lon)\n",
    "    return res\n",
    "\n",
    "def digitize_lat(x):\n",
    "    res = np.digitize(x, bins_lat)\n",
    "    return res\n",
    "\n",
    "spark.udf.register(\"udf_digitize_lon\", digitize_lon, IntegerType())\n",
    "spark.udf.register(\"udf_digitize_lat\", digitize_lat, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    udf_digitize_lon(t0.pickup_longitude) pickup_longitude_inds,\n",
    "    udf_digitize_lat(t0.pickup_latitude) pickup_latitude_inds,\n",
    "    udf_digitize_lon(t0.dropoff_longitude) dropoff_longitude_inds,\n",
    "    udf_digitize_lat(t0.dropoff_latitude) dropoff_latitude_inds\n",
    "FROM tbl_df t0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def bin_lonlat(x,bins):\n",
    "    res = bins[x] if x<len(bins) else None\n",
    "    return res\n",
    "\n",
    "spark.udf.register(\"udf_bin_lon\", lambda x: bin_lonlat(x, bins_lon), DoubleType())\n",
    "spark.udf.register(\"udf_bin_lat\", lambda x: bin_lonlat(x, bins_lat), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    udf_bin_lon(t0.pickup_longitude_inds) pickup_longitude_bin,\n",
    "    udf_bin_lat(t0.pickup_latitude_inds) pickup_latitude_bin,\n",
    "    udf_bin_lon(t0.dropoff_longitude_inds) dropoff_longitude_bin,\n",
    "    udf_bin_lat(t0.dropoff_latitude_inds) dropoff_latitude_bin\n",
    "FROM tbl_df t0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = df.limit(10).toPandas()\n",
    "# df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ll = spark.read\\\n",
    "    .format(\"com.databricks.spark.csv\")\\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "    .load(\"/home/arditto_trianggada3/Workspace/ds-ovo-test/dataset/map_address.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ll.createOrReplaceTempView(\"tbl_df_ll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dln = np.round(bins_lon[1]-bins_lon[0],3)\n",
    "# dlt = np.round(bins_lat[1]-bins_lat[0],3)\n",
    "# minln = bins_lon[0]\n",
    "# minlt = bins_lat[0]\n",
    "# Nln = len(bins_lon)\n",
    "# Nlt = len(bins_lat)\n",
    "\n",
    "# # x = {\n",
    "# #     'pickup_longitude':-74.001366,\n",
    "# #     'pickup_latitude':40.727348,\n",
    "# #     'dropoff_longitude':-73.993782,\n",
    "# #     'dropoff_latitude':40.727249\n",
    "# # }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def idx_lonlat(lon,lat,bins_lon,bins_lat):\n",
    "#     dln = np.round(bins_lon[1]-bins_lon[0],3)\n",
    "#     dlt = np.round(bins_lat[1]-bins_lat[0],3)\n",
    "#     minln = bins_lon[0]\n",
    "#     minlt = bins_lat[0]\n",
    "#     Nln = len(bins_lon)\n",
    "#     Nlt = len(bins_lat)\n",
    "#     res = (int(np.round((lon - bins_lon[0])/dln)))*Nlt + int(np.round((lat - bins_lat[0])/dlt))\n",
    "#     return res\n",
    "\n",
    "# spark.udf.register(\"udf_idx_lonlat\", lambda x: idx_lonlat(x, bins_lon,bins_lat), DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = spark.sql(\"\"\"\n",
    "# SELECT\n",
    "#     *,\n",
    "#     udf_idx_lonlat(t0.pickup_longitude,  t0.pickup_latitude) pickup_addr_idx,\n",
    "#     udf_idx_lonlat(t0.dropoff_longitude, t0.dropoff_latitude) dropoff_addr_idx\n",
    "# FROM tbl_df t0\n",
    "# \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    t0.*,\n",
    "    t1.addr_zipcode pickup_addr_zipcode,\n",
    "    t1.addr_place pickup_addr_place,\n",
    "    t1.addr_neighborhood pickup_addr_neighborhood,\n",
    "    t1.addr_sublocal pickup_addr_sublocal,\n",
    "    t1.addr_local pickup_addr_local,\n",
    "    t1.addr_administrative_area_level_2 pickup_addr_administrative_area_level_2,\n",
    "    t2.addr_zipcode dropoff_addr_zipcode,\n",
    "    t2.addr_place dropoff_addr_place,\n",
    "    t2.addr_neighborhood dropoff_addr_neighborhood,\n",
    "    t2.addr_sublocal dropoff_addr_sublocal,\n",
    "    t2.addr_local dropoff_addr_local,\n",
    "    t2.addr_administrative_area_level_2 dropoff_addr_administrative_area_level_2\n",
    "FROM tbl_df t0\n",
    "LEFT JOIN tbl_df_ll t1 ON (t0.pickup_longitude_bin = t1.longitude) AND (t0.pickup_latitude_bin = t1.latitude)\n",
    "LEFT JOIN tbl_df_ll t2 ON (t0.dropoff_longitude_bin = t2.longitude) AND (t0.dropoff_latitude_bin = t2.latitude)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in [\"pickup_longitude_inds\",\"pickup_latitude_inds\",\"dropoff_longitude_inds\",\"dropoff_latitude_inds\"]:\n",
    "    df = df.drop(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    CONCAT(pickup_addr_zipcode,'_',dropoff_addr_zipcode) pickup_to_dropoff_zipcode,\n",
    "    CONCAT(pickup_addr_place,'_',dropoff_addr_place) pickup_to_dropoff_place,\n",
    "    CONCAT(pickup_addr_neighborhood,'_',dropoff_addr_neighborhood) pickup_to_dropoff_neighborhood,\n",
    "    CONCAT(pickup_addr_sublocal,'_',dropoff_addr_sublocal) pickup_to_dropoff_sublocal,\n",
    "    CONCAT(pickup_addr_local,'_',dropoff_addr_local) pickup_to_dropoff_local,\n",
    "    CONCAT(pickup_addr_administrative_area_level_2,'_',dropoff_addr_administrative_area_level_2) pickup_to_dropoff_administrative_area_level_2\n",
    "FROM tbl_df t0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getMonth(x):\n",
    "    res = pd.to_datetime(x).dt.month\n",
    "    return res\n",
    "def getDayOfWeek(x):\n",
    "    res = pd.to_datetime(x).dt.month\n",
    "    return res\n",
    "def getHour(x):\n",
    "    res = pd.to_datetime(x).dt.month\n",
    "    return res\n",
    "\n",
    "spark.udf.register(\"udf_getMonth\", lambda x: getMonth, IntegerType())\n",
    "spark.udf.register(\"udf_getDayOfWeek\", lambda x: getDayOfWeek, StringType())\n",
    "spark.udf.register(\"udf_getHour\", lambda x: getHour, IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    udf_getMonth(t0.pickup_datetime) pickup_month,\n",
    "    udf_getDayOfWeek(t0.pickup_datetime) pickup_dayofweek,\n",
    "    udf_getHour(t0.pickup_datetime) pickup_hour,\n",
    "    udf_getMonth(t0.dropoff_datetime) dropoff_month,\n",
    "    udf_getDayOfWeek(t0.dropoff_datetime) dropoff_dayofweek,\n",
    "    udf_getHour(t0.dropoff_datetime) dropoff_hour\n",
    "FROM tbl_df t0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x, y)>"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "us_holidays = holidays.UnitedStates()\n",
    "\n",
    "spark.udf.register(\"udf_is_public_holiday\", lambda x: 1 if x in us_holidays else 0, IntegerType())\n",
    "spark.udf.register(\"udf_is_weekend\", lambda x: 1 if x in ['Saturday','Sunday'] else 0, IntegerType())\n",
    "spark.udf.register(\"udf_is_holiday\", lambda x,y: max(x['is_public_holiday'],x['is_weekend']), IntegerType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    udf_is_public_holiday(t0.pickup_datetime) is_public_holiday,\n",
    "    udf_is_weekend(t0.pickup_dayofweek) is_weekend\n",
    "FROM tbl_df t0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    udf_is_holiday(t0.is_public_holiday,t0.is_weekend) is_holiday\n",
    "FROM tbl_df t0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.night(x, y)>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def late_night (x):\n",
    "    if (x <= 6) or (x >= 20):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def night (x,y):\n",
    "    if ((x <= 20) and (x >= 16)) and (not(y in ['Saturday','Sunday'])):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "spark.udf.register(\"udf_late_night\", late_night, IntegerType())\n",
    "spark.udf.register(\"udf_night\", night, IntegerType())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    udf_late_night(t0.pickup_hour) trip_night,\n",
    "    udf_night(t0.pickup_hour,t0.pickup_dayofweek) trip_late_night\n",
    "FROM tbl_df t0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.euclidan(pickup_lat, pickup_long, dropoff_lat, dropoff_long)>"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manhattan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n",
    "    return np.abs(dropoff_lat - pickup_lat) + np.abs(dropoff_long - pickup_long)\n",
    "\n",
    "def euclidan(pickup_lat, pickup_long, dropoff_lat, dropoff_long):\n",
    "    return (np.abs(pickup_lat-dropoff_lat) ** 2 + np.abs(pickup_long-dropoff_long)  ** 2) ** 0.5\n",
    "\n",
    "spark.udf.register(\"udf_manhattan\", manhattan, DoubleType())\n",
    "spark.udf.register(\"udf_euclidan\", euclidan, DoubleType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    *,\n",
    "    udf_manhattan(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude) trip_dist_manhattan,\n",
    "    udf_euclidan(pickup_latitude, pickup_longitude, dropoff_latitude, dropoff_longitude) trip_dist_euclidean\n",
    "FROM tbl_df t0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"tbl_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for c in [\"pickup_addr_idx\",\"dropoff_addr_idx\"]:\n",
    "#     df = df.drop(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
